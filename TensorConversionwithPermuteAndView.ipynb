{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorConversionwithPermuteAndView\n",
    "# 问题： 在pytorch中使用permute和view实现空间通道、特征通道或者batch通道之间的互相转换。\n",
    "*****************************************\n",
    "最近用pixel shuffle模块实现空间通道和特征通道之间的互相转换，由于自己的突发奇想，想利用空间通道和batch通道的互换将一些循环操作可变成并行操作（感觉就是在给自己找事）。问题不是很难，但是很容易粗心写错了转换顺序，从而使处理效果变差（虽然我后来改正了，训练效果也没有好，o(╥﹏╥)o）。这里给出我自己在check顺序时的代码，方便理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "code for pixel_shuffle from:  https://github.com/myungsub/CAIN/blob/master/model/common.py\n",
    "'''\n",
    "def pixel_shuffle(input, scale_factor):\n",
    "    batch_size, channels, in_height, in_width = input.size()\n",
    "\n",
    "    out_channels = int(int(channels / scale_factor) / scale_factor)\n",
    "    out_height = int(in_height * scale_factor)\n",
    "    out_width = int(in_width * scale_factor)\n",
    "\n",
    "    if scale_factor >= 1:\n",
    "        input_view = input.contiguous().view(batch_size, out_channels, scale_factor, scale_factor, in_height, in_width)\n",
    "        shuffle_out = input_view.permute(0, 1, 4, 2, 5, 3).contiguous()\n",
    "    else:\n",
    "        block_size = int(1 / scale_factor)\n",
    "        input_view = input.contiguous().view(batch_size, channels, out_height, block_size, out_width, block_size)\n",
    "        shuffle_out = input_view.permute(0, 1, 3, 5, 2, 4).contiguous()\n",
    "\n",
    "    return shuffle_out.view(batch_size, out_channels, out_height, out_width)\n",
    "\n",
    "class PixelShuffle(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(PixelShuffle, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return pixel_shuffle(x, self.scale_factor)\n",
    "    def extra_repr(self):\n",
    "        return 'scale_factor={}'.format(self.scale_factor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【懒得分解每个单元，一些解释就放在了代码的注释里，聪明的人一看就懂】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# convert (N,C,H,W) - (N,C*16,H//4,W//4)\n",
    "in_shuffler = PixelShuffle(1/4)\n",
    "# convert (N,C*16,H//4,W//4) - (N,C,H,W) \n",
    "out_shuffler = PixelShuffle(4)\n",
    "\n",
    "# generate a image set (2,3,1024,1024)\n",
    "color_image1 = torch.from_numpy(np.array(Image.open(\"/path/for/image1\")).astype(np.float32).transpose(2,0,1)/255.0).unsqueeze(0)\n",
    "color_image2 = torch.from_numpy(np.array(Image.open(\"/path/for/image1\")).astype(np.float32).transpose(2,0,1)/255.0).unsqueeze(0)\n",
    "color_image = torch.cat((color_image1,color_image2),0)\n",
    "color_image = f.interpolate(color_image,(1024,1024))\n",
    "# generate its coarse version \n",
    "color_std = f.interpolate(color_image,(256,256)).permute(0,2,3,1).numpy()\n",
    "\n",
    "color_image_patch = in_shuffler(color_image)\n",
    "print(color_image_patch.shape)\n",
    "# decompose the slices from the channel\n",
    "color_image_patch1 = color_image_patch.view(2,3,16,256,256)\n",
    "# convert it into the batch\n",
    "color_image_patch1 = color_image_patch1.permute(0,2,1,3,4).contiguous().view(-1,3,256,256)\n",
    "image_patch = color_image_patch1.permute(0,2,3,1).numpy()\n",
    "plt.figure(figsize=(16,32))\n",
    "for i in range(32):\n",
    "    plt.subplot(8,4,i+1)\n",
    "    # show the differenece between each slice from the fine version and its corresponding coarse version\n",
    "    plt.imshow(abs(image_patch[i]-color_std[i//16]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the origin data with the (N*16,C,H//4,W//4)\n",
    "color_image_fuse  = out_shuffler(color_image_patch1.view(2,16,3,256,256).permute(0,2,1,3,4).contiguous().view(2,-1,256,256))\n",
    "# reconstruct the origin data with the (N,C*16,H//4,W//4)\n",
    "color_image_fuse_gt = out_shuffler(color_image_patch)\n",
    "print(color_image_fuse.shape)\n",
    "\n",
    "image_fuse = color_image_fuse.permute(0,2,3,1).numpy()\n",
    "image_fuse_gt = color_image_fuse_gt.permute(0,2,3,1).numpy()\n",
    "plt.figure(figsize=(32,16))\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    print(image_fuse[i].shape)\n",
    "    # plot the difference between two reconstructed coarse images\n",
    "    plt.imshow(image_fuse[i]-image_fuse_gt[i])\n",
    "    print(image_fuse[i]-image_fuse_gt[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再后来，我还尝试将不同batch的特征通道进组合，举例就是,x1有x11、x12,x2有x21,x22，从(x11,x21) (x12,x22)变成（x11,x21）(x12,x21)(x11,x22)(x21,x22)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_set = torch.cat((color_image1.unsqueeze(2),color_image2.unsqueeze(2)),2)\n",
    "color_set_x = color_set[:,0,:,:,:].unsqueeze(1).unsqueeze(2).repeat(1,1,2,1,1,1)\n",
    "color_set_y = color_set[:,1,:,:,:].unsqueeze(1).unsqueeze(3).repeat(1,1,1,2,1,1)\n",
    "print(color_set_x.shape,color_set_y.shape)\n",
    "color_set_stack = torch.cat((color_set_x,color_set_y),1)\n",
    "print(color_set_stack.shape)\n",
    "image_fuse= color_set_stack.numpy()\n",
    "plt.figure(figsize=(16,12))\n",
    "for i in range(2):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    print(color_set_stack[0,i,:].shape)\n",
    "    plt.imshow(image_fuse[0,i,0,0])\n",
    "    plt.subplot(2,4,i+3)\n",
    "#     print(color_set_stack[0,i,:].shape)\n",
    "    plt.imshow(image_fuse[0,i,0,1])\n",
    "    plt.subplot(2,4,i+5)\n",
    "#     print(color_set_stack[0,i,:].shape)\n",
    "    plt.imshow(image_fuse[0,i,1,0])\n",
    "                          \n",
    "    plt.subplot(2,4,i+7)\n",
    "    plt.imshow(image_fuse[0,i,1,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
